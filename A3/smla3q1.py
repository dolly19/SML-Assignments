# -*- coding: utf-8 -*-
"""SMLA3Q1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/145gZ3G3jyfrZdPtTNcbmzWcukUcdda-3
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/gdrive')
# %cd '/content/gdrive/MyDrive/ML datasets/SML/cifar-10-batches-py'
# %ls

from math import *
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import pickle
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.metrics import confusion_matrix

"""#Question 1"""

def unpickle(file):
    with open(file, 'rb') as fo:
        dict = pickle.load(fo, encoding='latin1')
    return dict

#unpickling the data
batch_1 = unpickle("data_batch_1")
batch_2 = unpickle("data_batch_2")
batch_3 = unpickle("data_batch_3")
batch_4 = unpickle("data_batch_4")
batch_5 = unpickle("data_batch_5")
test_batch = unpickle("test_batch")
meta_data = unpickle('batches.meta')

print("Label Names:", meta_data['label_names'] )

#Reshape and transpose an image/array into (32,32,3)
images = batch_1['data']
images = images.reshape(len(images),3,32,32).transpose(0,2,3,1)
labels = batch_1['labels']
label_names = meta_data['label_names']

def visualize(label):
  j=1
  rows, columns = 1, 5
  fig=plt.figure(figsize=(10, 10))

  for i in range(len(images)):
    if(j==6):
      break
    if(labels[i] == label):
      fig.add_subplot(rows, columns, j)
      plt.imshow(images[i])
      j = j+1
      plt.xticks([])
      plt.yticks([])
      plt.title("{}".format(label_names[label]))
  plt.show()

#Visualizing 5 samples from each class in the form of images
for i in range(10):
  visualize(i)

#merging batches
train_x = []
train_y = []

train_x.extend(batch_1['data'])
train_x.extend(batch_2['data'])
train_x.extend(batch_3['data'])
train_x.extend(batch_4['data'])
train_x.extend(batch_5['data'])
train_x = np.array(train_x)

train_y.extend(batch_1['labels'])
train_y.extend(batch_2['labels'])
train_y.extend(batch_3['labels'])
train_y.extend(batch_4['labels'])
train_y.extend(batch_5['labels'])
train_y = np.array(train_y)
print(train_x.shape,train_y.shape)

test_x = test_batch['data']
test_y = test_batch['labels']

test_y = np.array(test_y)
print(test_x.shape,test_y.shape)

#applying LDA
LDA = LinearDiscriminantAnalysis()
LDA.fit(train_x,train_y)

#accuracy for testing dataset
print("Accuracy ",LDA.score(test_x, test_y))

#class-wise accuracy for testing dataset
y_pred = LDA.predict(test_x)
CM = confusion_matrix(test_y,y_pred)
n = len(CM)
print("Class-wise accuracy")
for i in range(n):
  s = CM[i].sum()
  accuracy = CM[i][i]/s
  print("Label",i," - ",accuracy)

CM