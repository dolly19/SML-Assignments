# -*- coding: utf-8 -*-
"""SML_A4_Q3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z47DknenTE4aRFd8FGWsLlO2aFBhqPfH
"""

from google.colab import drive
drive.mount('/content/gdrive')

!pip install -q idx2numpy

import matplotlib.pyplot as plt
import numpy as np
import idx2numpy
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers, losses
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Dense , Dropout
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

"""#Question 3

### AutoEncoder
"""

#loading the dataset
X_train = idx2numpy.convert_from_file('/content/gdrive/MyDrive/ML datasets/SML/mnist/train-images.idx3-ubyte')
Y_train = idx2numpy.convert_from_file('/content/gdrive/MyDrive/ML datasets/SML/mnist/train-labels.idx1-ubyte')
X_test = idx2numpy.convert_from_file('/content/gdrive/MyDrive/ML datasets/SML/mnist/t10k-images.idx3-ubyte')
Y_test = idx2numpy.convert_from_file('/content/gdrive/MyDrive/ML datasets/SML/mnist/t10k-labels.idx1-ubyte')

#normalizing the data
X_train = X_train/255.0
X_test = X_test/255.0

X_train.shape

#Reshaping the data from 3d to 2d
X_train = X_train.reshape(len(X_train),X_train.shape[1]*X_train.shape[2])
X_test = X_test.reshape(len(X_test),X_test.shape[1]*X_test.shape[2])
accuracy_list = list()

X_train.shape

# defining the autoencoder architecture using Keras
class Autoencoder(Model):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = tf.keras.Sequential([                             
          layers.Dense(512, input_shape=(784,), activation='relu'),
          layers.Dense(128, activation='relu'),
          layers.Dense(64, activation='relu'),
        ])
        self.decoder = tf.keras.Sequential([
          layers.Dense(128, input_shape=(64,), activation='relu'),
          layers.Dense(512, activation='relu'),
          layers.Dense(784, activation='relu'),
        ])

    def call(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded
    
autoEncoder = Autoencoder()

#compiling the model
autoEncoder.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy')
H = autoEncoder.fit(X_train, X_train,epochs=25, batch_size = 16, validation_data=(X_test, X_test))

# plotting epoch wise training loss of autoencoder
y1 = H.history['loss']
x1 = np.arange(0,25)
plt.plot(x1, y1)
plt.title('TRAINING LOSS')
plt.xlabel('EPOCHS')
plt.ylabel('CROSS ENTROPY LOSS')
plt.show()

train_encoded = autoEncoder.encoder.predict(X_train)
test_encoded = autoEncoder.encoder.predict(X_test)
y_train_encoded = pd.get_dummies(Y_train).to_numpy()
y_test_encoded = pd.get_dummies(Y_test).to_numpy()

# defining the MNIST Classifcation Model
model=Sequential()
model.add(Dense(32, input_shape=(64,), activation="relu"))
model.add(Dropout(0.3))
model.add(Dense(10,input_shape=(32,), activation="softmax"))
model._name="MNIST_Classifcation_Model"

#compiling the model
model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy')
h = model.fit(train_encoded, y_train_encoded, validation_data=(test_encoded, y_test_encoded),epochs=100, batch_size=50,
                   verbose = 1)

# plotting epoch wise training loss
figure, axis = plt.subplots(1, 2)

y1 = h.history['loss']
x1 = np.arange(0,100)
axis[0].plot(x1, y1)
axis[0].set_title('TRAINING LOSS')
axis[0].set_xlabel('EPOCHS')
axis[0].set_ylabel('CROSS ENTROPY LOSS')

y2 = h.history['val_loss']
x2 = np.arange(0,100)
axis[1].plot(x2, y2 ,color='red')
axis[1].set_title('TESTING LOSS')
axis[1].set_xlabel('EPOCHS')
axis[1].set_ylabel('CROSS ENTROPY LOSS')

plt.show()

pred = model.predict(test_encoded)
y_pred = np.array([np.argmax(i) for i in pred])

#testing accuracy
accuracy = accuracy_score(Y_test,y_pred)
print("Accuracy : ", accuracy)

#classwise testing accuracy
cm = confusion_matrix(Y_test,y_pred)
n = len(cm)
print("Class-wise accuracy")
for i in range(n):
  s = cm[i].sum()
  accuracy = cm[i][i]/s
  print("Label",i," - ",accuracy)